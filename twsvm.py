# -*- coding: utf-8 -*-
"""twsvm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zo5-SzBL5-dffqv_niLM2ntbdohW-wwq
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.utils.validation import check_X_y, check_array
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from scipy.optimize import minimize
import urllib.request
from io import StringIO
import time
import warnings
warnings.filterwarnings('ignore')

  #base implementation

class TwinSVM(BaseEstimator, ClassifierMixin):
    def __init__(self, c1=1.0, c2=1.0, epsilon=1e-5):
        self.c1 = c1
        self.c2 = c2
        self.epsilon = epsilon
        self.w1 = None
        self.b1 = None
        self.w2 = None
        self.b2 = None

    def _solve_problem(self, A, B, c):
        m1, n = A.shape
        m2, _ = B.shape

        H = np.column_stack([A, np.ones(m1)])
        G = np.column_stack([B, np.ones(m2)])

        HTH = H.T @ H + self.epsilon * np.eye(n + 1)

        try:
            inv_HTH = np.linalg.pinv(HTH)
        except:
            inv_HTH = np.linalg.pinv(HTH + 1e-6 * np.eye(n + 1))

        M = G @ inv_HTH @ G.T
        e = np.ones(m2)

        def dual_objective(alpha):
            return 0.5 * alpha.T @ M @ alpha - e.T @ alpha

        def dual_gradient(alpha):
            return M @ alpha - e

        alpha0 = np.ones(m2) * 0.1 * c
        bounds = [(0, c) for _ in range(m2)]

        res = minimize(dual_objective, alpha0, jac=dual_gradient,
                      method='L-BFGS-B', bounds=bounds,
                      options={'maxiter': 100, 'ftol': 1e-6})

        alpha_opt = np.clip(res.x, 0, c)
        u = -inv_HTH @ G.T @ alpha_opt

        return u[:-1], u[-1]

    def fit(self, X, y):
        X, y = check_X_y(X, y)
        self.classes_ = np.unique(y)

        class1_idx = (y == 1)
        class2_idx = (y == -1)

        A = X[class1_idx]
        B = X[class2_idx]

        self.w1, self.b1 = self._solve_problem(A, B, self.c1)
        self.w2, self.b2 = self._solve_problem(B, A, self.c2)

        return self

    def predict(self, X):
        X = check_array(X)

        dist1 = np.abs(X @ self.w1 + self.b1) / (np.linalg.norm(self.w1) + 1e-8)
        dist2 = np.abs(X @ self.w2 + self.b2) / (np.linalg.norm(self.w2) + 1e-8)

        return np.where(dist1 < dist2, 1, -1)

        #loading datasets

class DatasetLoader:
    def __init__(self):
        self.datasets = {}

    def load_all_datasets(self):
        datasets_to_load = [
            self._load_heart_statlog,
            self._load_heart_c,
            self._load_hepatitis,
            self._load_ionosphere,
            self._load_sonar,
            self._load_votes,
            self._load_australian,
            self._load_cmc
        ]

        for loader in datasets_to_load:
            loader()

        return self.datasets

    def _load_heart_statlog(self):
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat"
            data = pd.read_csv(url, sep='\s+', header=None)
            X = data.iloc[:, :-1].values
            y = data.iloc[:, -1].values
            y = np.where(y == 1, 1, -1)
            self.datasets['Heart-statlog'] = (X, y)
        except Exception as e:
            print(f"Heart-statlog failed: {e}")

    def _load_heart_c(self):
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
            columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',
                      'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']
            data = pd.read_csv(url, header=None, names=columns, na_values='?')
            data = data.dropna()
            X = data.iloc[:, :-1].values
            y = data.iloc[:, -1].values
            y = np.where(y > 0, 1, -1)
            self.datasets['Heart-c'] = (X, y)
        except Exception as e:
            print(f"Heart-c failed: {e}")

    def _load_hepatitis(self):
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/hepatitis/hepatitis.data"
            columns = ['class', 'age', 'sex', 'steroid', 'antivirals', 'fatigue', 'malaise',
                      'anorexia', 'liver_big', 'liver_firm', 'spleen_palpable', 'spiders',
                      'ascites', 'varices', 'bilirubin', 'alk_phosphate', 'sgot', 'albumin',
                      'protime', 'histology']
            data = pd.read_csv(url, header=None, names=columns, na_values='?')
            data = data.dropna()
            X = data.iloc[:, 1:].values
            y = data.iloc[:, 0].values
            y = np.where(y == 1, 1, -1)
            self.datasets['Hepatitis'] = (X, y)
        except Exception as e:
            print(f"Hepatitis failed: {e}")

    def _load_ionosphere(self):
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data"
            data = pd.read_csv(url, header=None)
            X = data.iloc[:, :-1].values
            y = data.iloc[:, -1].values
            y = np.where(y == 'g', 1, -1)
            self.datasets['Ionosphere'] = (X, y)
        except Exception as e:
            print(f"Ionosphere failed: {e}")

    def _load_sonar(self):
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data"
            data = pd.read_csv(url, header=None)
            X = data.iloc[:, :-1].values
            y = data.iloc[:, -1].values
            y = np.where(y == 'R', 1, -1)
            self.datasets['Sonar'] = (X, y)
        except Exception as e:
            print(f"Sonar failed: {e}")

    def _load_votes(self):
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data"
            columns = ['class'] + [f'vote_{i}' for i in range(1, 17)]
            data = pd.read_csv(url, header=None, names=columns, na_values='?')
            data = data.dropna()
            for col in data.columns[1:]:
                data[col] = data[col].map({'y': 1, 'n': 0})
            X = data.iloc[:, 1:].values
            y = data.iloc[:, 0].values
            y = np.where(y == 'republican', 1, -1)
            self.datasets['Votes'] = (X, y)
        except Exception as e:
            print(f"Votes failed: {e}")

    def _load_australian(self):
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/australian/australian.dat"
            data = pd.read_csv(url, sep='\s+', header=None)
            X = data.iloc[:, :-1].values
            y = data.iloc[:, -1].values
            y = np.where(y == 1, 1, -1)
            self.datasets['Australian'] = (X, y)
        except Exception as e:
            print(f"Australian failed: {e}")

    def _load_cmc(self):
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/cmc/cmc.data"
            columns = ['wife_age', 'wife_education', 'husband_education', 'children',
                      'wife_religion', 'wife_working', 'husband_occupation',
                      'standard_living', 'media_exposure', 'contraceptive_method']
            data = pd.read_csv(url, header=None, names=columns)
            X = data.iloc[:, :-1].values
            y = data.iloc[:, -1].values
            y = np.where(y == 1, 1, -1)
            self.datasets['CMC'] = (X, y)
        except Exception as e:
            print(f"CMC failed: {e}")

class TWSVMEvaluator:
    def __init__(self):
        self.paper_results = {
            'Heart-statlog': 84.44, 'Heart-c': 83.80, 'Hepatitis': 80.79,
            'Ionosphere': 88.03, 'Sonar': 77.26, 'Votes': 96.08,
            'Australian': 85.80, 'CMC': 67.28
        }

        self.paper_times = {
            'Heart-statlog': 0.1057, 'Heart-c': 0.1092, 'Hepatitis': 0.0493,
            'Ionosphere': 0.3459, 'Sonar': 0.1808, 'Votes': 0.0518,
            'Australian': 0.1924, 'CMC': 1.7546
        }

    def evaluate_twsvm(self, X, y, dataset_name, n_splits=5):
        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

        accuracies = []
        times = []

        for train_idx, test_idx in kf.split(X):
            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]

            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            start_time = time.time()
            twsvm = TwinSVM(c1=1.0, c2=1.0)
            twsvm.fit(X_train_scaled, y_train)
            training_time = time.time() - start_time

            accuracy = accuracy_score(y_test, twsvm.predict(X_test_scaled))

            accuracies.append(accuracy)
            times.append(training_time)

        return {
            'dataset': dataset_name,
            'samples': X.shape[0],
            'features': X.shape[1],
            'accuracy': np.mean(accuracies) * 100,
            'accuracy_std': np.std(accuracies) * 100,
            'training_time': np.mean(times),
            'paper_accuracy': self.paper_results.get(dataset_name),
            'paper_time': self.paper_times.get(dataset_name)
        }

def run_twsvm_evaluation():
    loader = DatasetLoader()
    datasets = loader.load_all_datasets()
    evaluator = TWSVMEvaluator()

    results = []
    for name, (X, y) in datasets.items():
        n_splits = 5 if X.shape[0] >= 100 else 3
        result = evaluator.evaluate_twsvm(X, y, name, n_splits)
        results.append(result)

    results_df = pd.DataFrame(results)

    results_df['speedup'] = results_df['paper_time'] / results_df['training_time']
    results_df['accuracy_diff'] = results_df['accuracy'] - results_df['paper_accuracy']

    return results_df

def print_results(results_df):
    print("TWSVM Evaluation Results")
    print("=" * 80)

    for _, row in results_df.iterrows():
        print(f"{row['dataset']}:")
        print(f"  Accuracy: {row['accuracy']:.2f}% (Paper: {row['paper_accuracy']}%)")
        print(f"  Time: {row['training_time']:.3f}s (Paper SVM: {row['paper_time']:.3f}s)")
        print(f"  Speedup: {row['speedup']:.2f}x")
        print()

    avg_accuracy = results_df['accuracy'].mean()
    avg_speedup = results_df['speedup'].mean()

    print(f"Average Accuracy: {avg_accuracy:.2f}%")
    print(f"Average Speedup: {avg_speedup:.2f}x")
    print(f"Paper Claimed Speedup: 4.00x")
    print(f"Achieved: {avg_speedup/4.0*100:.1f}% of claimed speedup")

if __name__ == "__main__":
    results = run_twsvm_evaluation()
    print_results(results)
    results.to_csv('twsvm_results.csv', index=False)